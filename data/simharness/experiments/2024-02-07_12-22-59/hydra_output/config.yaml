simulation:
  train:
    area:
      screen_size:
        _target_: builtins.tuple
        _args_:
        - - ${simulation.screen_height}
          - ${simulation.screen_width}
    display:
      fire_size: 1
      control_line_size: 3
      agent_size: 4
      rescale_factor: 4
    simulation:
      update_rate: 1
      runtime: 24hr
      headless: true
      record: true
      save_data: false
      draw_spread_graph: false
      data_type: npy
      sf_home: ${oc.env:HOME}/.simfire
    mitigation:
      ros_attenuation: false
    operational:
      seed: null
      latitude: 36.09493
      longitude: -120.52193
      height: 5000
      width: 5000
      resolution: 30
      year: 2019
    terrain:
      topography:
        type: operational
        functional:
          function: perlin
          perlin:
            octaves: 3
            persistence: 0.7
            lacunarity: 2.0
            seed: 827
            range_min: 100.0
            range_max: 300.0
          gaussian:
            amplitude: 500
            mu_x: 50
            mu_y: 50
            sigma_x: 50
            sigma_y: 50
      fuel:
        type: operational
        functional:
          function: chaparral
          chaparral:
            seed: 1113
    fire:
      fire_initial_position:
        type: random
        static:
          position:
            _target_: builtins.tuple
            _args_:
            - - 0
              - 0
        random:
          seed: ${simulation.fire_start_seed}
      max_fire_duration: 4
      diagonal_spread: false
    environment:
      moisture: 0.03
    wind:
      function: simple
      cfd:
        time_to_train: 1000
        iterations: 1
        scale: 1
        timestep_dt: 1.0
        diffusion: 0.0
        viscosity: 1.0e-07
        speed: 19
        direction: north
      simple:
        speed: 1
        direction: 135.0
      perlin:
        speed:
          seed: 2345
          scale: 400
          octaves: 3
          persistence: 0.7
          lacunarity: 2.0
          min: 7
          max: 47
        direction:
          seed: 650
          scale: 1500
          octaves: 2
          persistence: 0.9
          lacunarity: 1.0
          min: 0.0
          max: 360.0
  eval:
    area:
      screen_size:
        _target_: builtins.tuple
        _args_:
        - - ${simulation.screen_height}
          - ${simulation.screen_width}
      pixel_scale: 50
    display:
      fire_size: 1
      control_line_size: 3
      agent_size: 4
      rescale_factor: 2
    simulation:
      update_rate: 1
      runtime: 24hr
      headless: true
      record: true
      save_data: false
      draw_spread_graph: false
      data_type: npy
      sf_home: ${oc.env:HOME}/.simfire
    mitigation:
      ros_attenuation: false
    operational:
      seed: null
      latitude: 36.09493
      longitude: -120.52193
      height: 5000
      width: 5000
      resolution: 30
      year: 2019
    terrain:
      topography:
        type: operational
        functional:
          function: perlin
          perlin:
            octaves: 3
            persistence: 0.7
            lacunarity: 2.0
            seed: 827
            range_min: 100.0
            range_max: 300.0
          gaussian:
            amplitude: 500
            mu_x: 50
            mu_y: 50
            sigma_x: 50
            sigma_y: 50
      fuel:
        type: operational
        functional:
          function: chaparral
          chaparral:
            seed: 1113
    fire:
      fire_initial_position:
        type: random
        static:
          position:
            _target_: builtins.tuple
            _args_:
            - - 0
              - 0
        random:
          seed: ${simulation.fire_start_seed}
      max_fire_duration: 4
      diagonal_spread: false
    environment:
      moisture: 0.03
    wind:
      function: simple
      cfd:
        time_to_train: 1000
        iterations: 1
        scale: 1
        timestep_dt: 1.0
        diffusion: 0.0
        viscosity: 1.0e-07
        speed: 19
        direction: north
      simple:
        speed: 1
        direction: 135.0
      perlin:
        speed:
          seed: 2345
          scale: 400
          octaves: 3
          persistence: 0.7
          lacunarity: 2.0
          min: 7
          max: 47
        direction:
          seed: 650
          scale: 1500
          octaves: 2
          persistence: 0.9
          lacunarity: 1.0
          min: 0.0
          max: 360.0
  screen_size: 128
  screen_height: ${.screen_size}
  screen_width: ${.screen_size}
  fire_start_seed: 2
training:
  model:
    conv_filters:
    - - 16
      - - 2
        - 2
      - 2
    - - 32
      - - 2
        - 2
      - 2
    - - 64
      - - 4
        - 4
      - 4
    - - 256
      - - 8
        - 8
      - 1
  train_batch_size: 1000
environment:
  env_config:
    sim:
      _target_: simfire.sim.simulation.FireSimulation
      config:
        _target_: simfire.utils.config.Config
        config_dict: ${simulation.train}
    movements:
    - none
    - up
    - down
    - left
    - right
    interactions:
    - fireline
    - none
    - wetline
    attributes:
    - fire_map
    - elevation
    - w_0
    - sigma
    - delta
    - M_x
    normalized_attributes:
    - elevation
    agent_speed: 4
    harness_analytics_partial:
      _target_: simharness2.analytics.harness_analytics.ReactiveHarnessAnalytics
      _partial_: true
      sim_analytics_partial:
        _target_: simharness2.analytics.simulation_analytics.FireSimulationAnalytics
        _partial_: true
        agent_analytics_partial:
          _target_: simharness2.analytics.agent_analytics.ReactiveAgentAnalytics
          _partial_: true
          movement_types: ${....movements}
          interaction_types: ${....interactions}
    reward_cls_partial:
      _target_: simharness2.rewards.base_reward.SimpleReward
      _partial_: true
    agent_initialization_method: manual
    initial_agent_positions:
    - - 50
      - 50
    action_space_cls:
      _target_: hydra.utils.get_class
      path: gymnasium.spaces.Discrete
  env: simharness2.environments.ReactiveHarness
  env_task_fn: null
  render_env: false
  clip_rewards: null
  normalize_actions: true
  disable_env_checking: false
  is_atari: false
framework:
  framework: torch
  eager_tracing: false
rollouts:
  num_rollout_workers: 8
  num_envs_per_worker: 1
  rollout_fragment_length: auto
  batch_mode: truncate_episodes
  validate_workers_after_construction: true
  ignore_worker_failures: false
  recreate_failed_workers: false
  restart_failed_sub_environments: false
  compress_observations: false
evaluation:
  evaluation_config:
    env: ${environment.env}
    env_config:
      sim:
        _target_: simfire.sim.simulation.FireSimulation
        config:
          _target_: simfire.utils.config.Config
          config_dict: ${simulation.eval}
      movements:
      - none
      - up
      - down
      - left
      - right
      interactions:
      - fireline
      - none
      - wetline
      attributes:
      - fire_map
      - elevation
      - w_0
      - sigma
      - delta
      - M_x
      normalized_attributes:
      - elevation
      agent_speed: 4
      harness_analytics_partial:
        _target_: simharness2.analytics.harness_analytics.ReactiveHarnessAnalytics
        _partial_: true
        sim_analytics_partial:
          _target_: simharness2.analytics.simulation_analytics.FireSimulationAnalytics
          _partial_: true
          agent_analytics_partial:
            _target_: simharness2.analytics.agent_analytics.ReactiveAgentAnalytics
            _partial_: true
            movement_types: ${....movements}
            interaction_types: ${....interactions}
            save_history: true
          save_history: true
      reward_cls_partial:
        _target_: simharness2.rewards.base_reward.SimpleReward
        _partial_: true
      agent_initialization_method: manual
      initial_agent_positions:
      - - 50
        - 50
      action_space_cls:
        _target_: hydra.utils.get_class
        path: gymnasium.spaces.Discrete
      benchmark_sim: ${.sim}
      in_evaluation: true
  evaluation_interval: 2
  evaluation_duration: 1
  evaluation_duration_unit: episodes
  evaluation_num_workers: 1
  enable_async_evaluation: false
exploration:
  exploration_config:
    type: EpsilonGreedy
    initial_epsilon: 1.0
    final_epsilon: 0.05
    warmup_timesteps: 1000000
    epsilon_timesteps: 10000000
  explore: true
resources:
  num_gpus: 0
  num_cpus_per_worker: 1
  num_gpus_per_worker: 0
  num_cpus_for_local_worker: 1
  placement_strategy: PACK
tunables:
  training:
    lr:
      type: loguniform
      values:
      - 0.0001
      - 0.01
    gamma:
      type: uniform
      values:
      - 0.5
      - 0.9
    train_batch_size:
      type: choice
      values:
      - 16
      - 32
      - 64
      - 128
aim:
  run_hash: null
  repo: ${cli.data_dir}/simharness/aim
  experiment: debug_alex
  system_tracking_interval: null
  log_system_params: true
  capture_terminal_logs: true
  log_hydra_config: false
cli:
  mode: train
  data_dir: data
algo:
  name: PPO
  checkpoint_path: null
run:
  name: null
  storage_path: ${hydra:run.dir}
checkpoint:
  checkpoint_frequency: 20
  num_to_keep: null
stop_conditions:
  training_iteration: 4
  timesteps_total: 2000000000
  episodes_total: 1000000
  episode_reward_mean: 10000000
debugging:
  log_level: INFO
  log_sys_usage: true
  seed: 2000
  logger_config:
    type:
      _target_: hydra.utils.get_class
      path: ray.tune.logger.TBXLogger
    logdir: ${cli.data_dir}/simharness/logs
